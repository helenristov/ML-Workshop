{"cells":[{"cell_type":"markdown","source":["### In this notebook, we'll aim to create a Blob Storage account, upload a CSV file, and read the data in it"],"metadata":{}},{"cell_type":"markdown","source":["#### Step 1 - Creating Blob Storage\n\nPlease follow the MSFT Azure documentation on creating a Blob Storage account: https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-portal\n\nOnce you have successfully created your Storage Account, please upload a CSV file to the new blob storage account using the Azure portal."],"metadata":{}},{"cell_type":"markdown","source":["#### Step 2 - Mount Blob Storage to DBFS\n\nLooking at the documentation, please mount your Blob Storage as a new DBFS mount: https://docs.databricks.com/spark/latest/data-sources/azure/azure-storage.html#mount-an-azure-blob-storage-container"],"metadata":{}},{"cell_type":"code","source":["#Replace the parameters below with your own blob storage container\n\nSTORAGE_ACCOUNT = \"\"\nCONTAINER = \"\"\nMOUNT_POINT = \"/mnt/databricks-workshop-self-upload\"\nSAS_KEY = \"\""],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["#Define strings to be passed to the mount function\nsource_str = \"wasbs://{container}@{storage_acct}.blob.core.windows.net/\".format(container=CONTAINER, storage_acct=STORAGE_ACCOUNT)\nconf_key = \"fs.azure.sas.{container}.{storage_acct}.blob.core.windows.net\".format(container=CONTAINER, storage_acct=STORAGE_ACCOUNT)\n\n#Run the mount function using template in the documentation\ntry:\n  dbutils.fs.mount(\n    source = source_str,\n    mount_point = MOUNT_POINT,\n    extra_configs = {conf_key: SAS_KEY}\n  )\nexcept Exception as e:\n  print(\"ERROR: {} already mounted. Run previous cells to unmount first\".format(MOUNT_POINT))"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["#### Step 3 - Reading the CSV\n\nIf you're stuck, you can find examples here: https://docs.azuredatabricks.net/spark/latest/data-sources/read-csv.html#read-file-in-any-language"],"metadata":{}},{"cell_type":"code","source":["csvpath = \"\"\n\ndf = spark.read.csv(csvpath)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["display(df)"],"metadata":{},"outputs":[],"execution_count":8}],"metadata":{"name":"2-03 Lab - Reading a CSV","notebookId":1685127807621182},"nbformat":4,"nbformat_minor":0}
